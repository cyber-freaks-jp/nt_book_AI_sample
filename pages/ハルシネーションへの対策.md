# ハルシネーションへの対策

## ハルシネーションとは

ハルシネーション（幻覚）とは、AIモデルが実際には存在しない情報を生成したり、誤った情報を確信を持って提示したりする現象です。これは、AI駆動開発において最も注意すべき課題の一つです。

### 具体例

```
あなた：「現在の日本の総理大臣は？」
AI：「伊藤博文です」
```

## ハルシネーションの3つの種類

### 1. 事実誤認型ハルシネーション

存在しない情報や誤った情報を生成します。

**例**：
- 存在しないライブラリやAPIを提案
- 誤ったバージョン情報
- 架空の引用や参考文献

```
「express-super-validator というライブラリを使うと簡単です」
→ そんなライブラリは存在しない
```

### 2. 論理矛盾型ハルシネーション

矛盾する情報や一貫性のない説明を生成します。

**例**：
```
AIの回答：
「このAPIは同期的に動作します。
 そのため、await キーワードを使用して非同期に呼び出す必要があります。」

→ 同期なのに非同期？矛盾している
```

### 3. 過剰確信型ハルシネーション

不確かな情報を確実であるかのように提示します。

**例**：
```
「このコードは100%安全です。セキュリティの問題は一切ありません。」

→ 実際にはSQLインジェクション脆弱性がある
```


## ハルシネーションへの対策

### 対策1：具体的なプロンプトを書く

```
❌ 悪い例：
「データベースを設計して」

✅ 良い例：
「@Docs/要件定義書.md をもとに、
 PostgreSQL でユーザー管理システムのデータベースを設計してください。
 以下のテーブルが必要です：
 - users（id, email, password_hash, created_at）
 - profiles（user_id, name, bio）
 ER図をMermaid形式で作成し、各テーブルの説明を追加してください。」
```

### 対策2：「不確かな場合は明示して」と指示

```
プロンプト例：
「Node.jsで画像処理をしたいです。
 推奨ライブラリを教えてください。

 ⚠️ 重要：
 - 確実な情報のみを提供してください
 - 不確かな情報は「確認が必要」と明示してください
 - 存在しないライブラリは提案しないでください」
```

### 対策3：検証を依頼する

```
プロンプト例：
「先ほど提案された sort_array_fast() 関数について、
 以下を確認してください：
 1. この関数は本当にPythonの組み込み関数ですか？
 2. 公式ドキュメントのURLを提示できますか？
 3. 代替案はありますか？」
```


## **重要な原則**

1. **AIを過信しない**：AIも間違える。その前提でレビューやテストをする
2. **必ず検証する**：公式ドキュメントや動作の確認

ハルシネーションは完全には防げませんが、適切な対策と検証により、そのリスクを大幅に削減できます。
